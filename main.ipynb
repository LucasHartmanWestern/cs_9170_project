{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import DQNAgent\n",
    "from ppo_agent import PPOAgent\n",
    "from ffnn_agent import FFNNAgent\n",
    "from data_processing import preprocess_all_data, load_preprocessed_dataset, get_activity, get_column_units\n",
    "from data_processing import load_preprocessed_dataset, get_xy_from_data, get_activity, get_column_units\n",
    "from visualize import visualize_results, visualize_training, visualize_preprocessed_data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Preprocessed Dataset Info ----\n",
      "Number of rows: 61000\n",
      "Number of columns: 39\n",
      "-----------------------------------\n",
      "'Resting HR' unique values: [75 74 68 58 70 60]\n",
      "'Max HR' unique values: [193 195 189 196 194 197]\n",
      "'Age' unique values: [27 25 31 24 26 23]\n",
      "'Weight' unique values: [83 78 92 95 73 69 86]\n",
      "'Height' unique values: [182 169 187 194 180 183 173]\n",
      "\n",
      "training samples: 42700\n",
      "validation samples: 9150\n",
      "testing samples: 9150\n",
      "\n",
      "(42700, 5)\n",
      "(42700, 34)\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed dataset\n",
    "df = load_preprocessed_dataset()\n",
    "target_features = [\"Resting HR\", \"Max HR\", \"Age\", \"Weight\", \"Height\"]\n",
    "\n",
    "# Print unique values of target features\n",
    "for feature in target_features:\n",
    "    print(f\"'{feature}' unique values: {df[feature].unique()}\")\n",
    "\n",
    "# Split into 70% train, 15% val, 15% test with stratification\n",
    "df_train, df_temp = train_test_split(\n",
    "    df, test_size=0.30, stratify=df[target_features], random_state=42\n",
    ")\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp, test_size=0.50, stratify=df_temp[target_features], random_state=42\n",
    ")\n",
    "\n",
    "# Get X and y data from training, validation, and testing sets\n",
    "x_train, y_train = get_xy_from_data(df_train, target_features)\n",
    "x_val, y_val = get_xy_from_data(df_val, target_features)\n",
    "x_test, y_test = get_xy_from_data(df_test, target_features)\n",
    "\n",
    "print(f\"\\ntraining samples: {x_train.shape[0]}\")\n",
    "print(f\"validation samples: {x_val.shape[0]}\")\n",
    "print(f\"testing samples: {x_test.shape[0]}\\n\")\n",
    "\n",
    "# Make y_train 2d\n",
    "# y_train = y_train.values.reshape(-1, 1)\n",
    "# y_val = y_val.values.reshape(-1, 1)\n",
    "# y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "continuous_columns = [\n",
    "    'Timestamp', 'Heart Rate', 'Hand Sensor - Temperature',\n",
    "    'Hand Sensor - Accelerometer - X', 'Hand Sensor - Accelerometer - Y',\n",
    "    'Hand Sensor - Accelerometer - Z', 'Hand Sensor - Gyroscope - X',\n",
    "    'Hand Sensor - Gyroscope - Y', 'Hand Sensor - Gyroscope - Z',\n",
    "    'Hand Sensor - Magnetometer - X', 'Hand Sensor - Magnetometer - Y',\n",
    "    'Hand Sensor - Magnetometer - Z', 'Chest Sensor - Temperature',\n",
    "    'Chest Sensor - Accelerometer - X', 'Chest Sensor - Accelerometer - Y',\n",
    "    'Chest Sensor - Accelerometer - Z', 'Chest Sensor - Gyroscope - X',\n",
    "    'Chest Sensor - Gyroscope - Y', 'Chest Sensor - Gyroscope - Z',\n",
    "    'Chest Sensor - Magnetometer - X', 'Chest Sensor - Magnetometer - Y',\n",
    "    'Chest Sensor - Magnetometer - Z', 'Ankle Sensor - Temperature',\n",
    "    'Ankle Sensor - Accelerometer - X', 'Ankle Sensor - Accelerometer - Y',\n",
    "    'Ankle Sensor - Accelerometer - Z', 'Ankle Sensor - Gyroscope - X',\n",
    "    'Ankle Sensor - Gyroscope - Y', 'Ankle Sensor - Gyroscope - Z',\n",
    "    'Ankle Sensor - Magnetometer - X', 'Ankle Sensor - Magnetometer - Y',\n",
    "    'Ankle Sensor - Magnetometer - Z', 'Height', 'Weight',\n",
    "    'Resting HR', 'Max HR'\n",
    "]\n",
    "\n",
    "discrete_columns = [\n",
    "    'Age', 'Sex - Female'\n",
    "]\n",
    "\n",
    "#discrete action size columns\n",
    "dqn_config = {\n",
    "    'state_size': 5,  \n",
    "    'action_size': len(discrete_columns),  \n",
    "    'hidden_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'gamma': 0.99,\n",
    "    'batch_size': 32,\n",
    "    'memory_size': 10000,\n",
    "    'epsilon_start': 1.0,\n",
    "    'epsilon_min': 0.01,\n",
    "    'epsilon_decay': 0.995\n",
    "}\n",
    "\n",
    "\n",
    "#continuous\n",
    "ppo_config = {\n",
    "    'state_size': 5,  \n",
    "    'action_size': len(continuous_columns),   \n",
    "    'hidden_size': 64,\n",
    "    'lr': 3e-4,\n",
    "    'gamma': 0.99,\n",
    "    'clip_epsilon': 0.2,\n",
    "    'update_epochs': 4,\n",
    "    'batch_size': 64,\n",
    "    'c1': 0.5,\n",
    "    'c2': 0.01\n",
    "}\n",
    "classes = [1, 2, 3, 17, 16, 13, 4, 7, 6]\n",
    "ffnn_config = {\n",
    "    'input_size': df.shape[1] - 1,\n",
    "    'hidden_sizes': [16, 16],\n",
    "    'output_size': len(classes),\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'type': 'classification',\n",
    "    'classes': classes\n",
    "}\n",
    "\n",
    "accuracy_reward_multiplier = 100\n",
    "\n",
    "synthetic_data_amount = 1000\n",
    "num_episodes = 100\n",
    "\n",
    "dqn_agent = DQNAgent(**dqn_config)\n",
    "ppo_agent = PPOAgent(**ppo_config)\n",
    "ffnn_agent = FFNNAgent(**ffnn_config)\n",
    "ffnn_agent_og = FFNNAgent(**ffnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 196\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m results \u001b[38;5;241m=\u001b[39m train_agents(x_train, y_train, x_val, y_val, x_test, y_test, dqn_agent, ppo_agent, ffnn_agent)\n\u001b[1;32m    197\u001b[0m dqn_agent\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn_trained_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    198\u001b[0m ppo_agent\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_trained_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 97\u001b[0m, in \u001b[0;36mtrain_agents\u001b[0;34m(x_train, y_train, x_val, y_val, x_test, y_test, dqn_agent, ppo_agent, ffnn_agent, episodes, save_path)\u001b[0m\n\u001b[1;32m     95\u001b[0m sex_female_idx \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex - Female\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m mf_ratio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(x_train\u001b[38;5;241m.\u001b[39miloc[:, sex_female_idx])\n\u001b[0;32m---> 97\u001b[0m state \u001b[38;5;241m=\u001b[39m generate_state(x_train, mf_ratio, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Generating Synthetic Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m, in \u001b[0;36mgenerate_state\u001b[0;34m(df, mf_ratio, n_samples)\u001b[0m\n\u001b[1;32m     58\u001b[0m male_female_ratio \u001b[38;5;241m=\u001b[39m mf_ratio \n\u001b[1;32m     59\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m n_samples\n\u001b[0;32m---> 60\u001b[0m age \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m     61\u001b[0m activity_id \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([timestamp, male_female_ratio, num_samples, age, activity_id])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "\n",
    "def evaluate_ffnn(ffnn_agent, data, labels):\n",
    "    # Ensure data and labels are NumPy arrays\n",
    "    if isinstance(data, (pd.DataFrame, pd.Series)):\n",
    "        data = data.to_numpy()\n",
    "    if isinstance(labels, (pd.Series, pd.DataFrame)):\n",
    "        labels = labels.to_numpy().reshape(-1)\n",
    "\n",
    "    # Use the agent's predict function to get predictions\n",
    "    predicted_classes = ffnn_agent.predict(data)\n",
    "    \n",
    "    # Convert labels to numpy array if they're not already\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "    \n",
    "    # Ensure same shape\n",
    "    if predicted_classes.shape != labels.shape:\n",
    "        labels = labels.reshape(-1)\n",
    "        predicted_classes = predicted_classes.reshape(-1)\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    correct = (predicted_classes == labels).sum()\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Compute accuracy for females (last column == 1)\n",
    "    female_mask = data[:, -1] == 1  # \"Sex - Female\" is the last column\n",
    "    \n",
    "    if female_mask.sum() > 0:\n",
    "        female_preds = predicted_classes[female_mask]\n",
    "        female_labels = labels[female_mask]\n",
    "        female_correct = (female_preds == female_labels).sum()\n",
    "        female_total = len(female_labels)\n",
    "        female_accuracy = female_correct / female_total\n",
    "    else:\n",
    "        female_accuracy = float('nan')  # No females in the data\n",
    "\n",
    "    return accuracy, female_accuracy\n",
    "\n",
    "\n",
    "def plot_ffnn_losses(losses):\n",
    "    # Plot training loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.title('FFNN Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_state(df, mf_ratio, n_samples):\n",
    "    timestamp = np.random.uniform(df['Timestamp'].min(), df['Timestamp'].max())\n",
    "    male_female_ratio = mf_ratio \n",
    "    num_samples = n_samples\n",
    "    age = np.random.uniform(df['Age'].min(), df['Age'].max())\n",
    "    activity_id = np.random.choice([1, 2, 3, 17, 16, 13, 4, 7, 6])\n",
    "    return np.array([timestamp, male_female_ratio, num_samples, age, activity_id])\n",
    "\n",
    "\n",
    "def compute_mini_reward(synthetic_data, mf_ratio):\n",
    "    column_std = np.std(synthetic_data, axis=0).mean()\n",
    "    gaussian_penalty = np.exp(-((mf_ratio - 0.5) ** 2) / 0.1)\n",
    "    return column_std + gaussian_penalty\n",
    "\n",
    "\n",
    "def train_agents(x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "                 dqn_agent, ppo_agent, ffnn_agent, episodes=num_episodes,\n",
    "                 save_path='training_metrics.json'):\n",
    "\n",
    "    # Normalize y arrays to shape (n, 1)\n",
    "    for var in ['y_train', 'y_val', 'y_test']:\n",
    "        val = locals()[var]\n",
    "        if isinstance(val, pd.Series):\n",
    "            locals()[var] = val.to_numpy().reshape(-1, 1)\n",
    "        elif isinstance(val, pd.DataFrame):\n",
    "            locals()[var] = val.to_numpy()\n",
    "\n",
    "    rewards = []\n",
    "    val_accuracies = []\n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "    val_female_accuracies = []\n",
    "    test_female_accuracies = []\n",
    "    train_female_accuracies = []\n",
    "\n",
    "    synthetic_data = []\n",
    "    synthetic_labels = []\n",
    "\n",
    "    # Initial male-female ratio\n",
    "    sex_female_idx = x_train.columns.get_loc('Sex - Female')\n",
    "    mf_ratio = np.mean(x_train.iloc[:, sex_female_idx])\n",
    "    state = generate_state(x_train, mf_ratio, 0)\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        print(f\"Episode {episode + 1}/{episodes}: Generating Synthetic Data\")\n",
    "        for i in range(synthetic_data_amount):\n",
    "            if synthetic_data:\n",
    "                synthetic_array = np.array(synthetic_data)\n",
    "                if synthetic_array.ndim == 1:\n",
    "                    synthetic_array = synthetic_array.reshape(1, -1)\n",
    "                combined_array = np.vstack([x_train.to_numpy(), synthetic_array])\n",
    "                combined = pd.DataFrame(combined_array, columns=x_train.columns)\n",
    "            else:\n",
    "                combined = x_train.copy()\n",
    "\n",
    "            sex_female_idx = combined.columns.get_loc('Sex - Female')\n",
    "            mf_ratio = np.mean(combined.iloc[:, sex_female_idx])\n",
    "\n",
    "            discrete_action = np.array(dqn_agent.predict(state), ndmin=1)\n",
    "            continuous_action = np.array(ppo_agent.predict(state), ndmin=1)\n",
    "\n",
    "            synthetic_row = np.zeros(x_train.shape[1])\n",
    "            discrete_indices = x_train.columns.get_indexer(discrete_columns)\n",
    "            continuous_indices = x_train.columns.get_indexer(continuous_columns)\n",
    "            synthetic_row[discrete_indices] = discrete_action\n",
    "            synthetic_row[continuous_indices] = continuous_action\n",
    "\n",
    "            synthetic_data.append(synthetic_row)\n",
    "            synthetic_labels.append(state[4])  # activity ID\n",
    "\n",
    "            mini_reward = compute_mini_reward(np.array(synthetic_data), mf_ratio)\n",
    "            done = i == synthetic_data_amount - 1\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode {episode + 1}/{episodes}: Training FFNN\")\n",
    "                \n",
    "                ffnn_agent.reset()\n",
    "\n",
    "                synthetic_data_np = np.array(synthetic_data)\n",
    "                synthetic_labels_np = np.array(synthetic_labels).reshape(-1, 1)\n",
    "\n",
    "                combined_data = np.vstack([x_train.to_numpy(), synthetic_data_np])\n",
    "                combined_labels = np.vstack([y_train, synthetic_labels_np])\n",
    "\n",
    "                # Shuffle combined training data\n",
    "                indices = np.arange(combined_data.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "                combined_data = combined_data[indices]\n",
    "                combined_labels = combined_labels[indices]\n",
    "\n",
    "                # Train FFNN\n",
    "                losses = ffnn_agent.train(combined_data, combined_labels)\n",
    "                plot_ffnn_losses(losses)\n",
    "\n",
    "                print(f\"Episode {episode + 1}/{episodes}: Evaluating FFNN\")\n",
    "\n",
    "                train_accuracy, train_female_accuracy = evaluate_ffnn(ffnn_agent, x_train, y_train)\n",
    "                val_accuracy, val_female_accuracy = evaluate_ffnn(ffnn_agent, x_val, y_val)\n",
    "                test_accuracy, test_female_accuracy = evaluate_ffnn(ffnn_agent, x_test, y_test)\n",
    "\n",
    "                reward = val_accuracy * accuracy_reward_multiplier\n",
    "                reward += mini_reward\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                val_accuracies.append(val_accuracy)\n",
    "                test_accuracies.append(test_accuracy)\n",
    "                train_female_accuracies.append(train_female_accuracy)\n",
    "                val_female_accuracies.append(val_female_accuracy)\n",
    "                test_female_accuracies.append(test_female_accuracy)\n",
    "\n",
    "                print(f\"Episode {episode + 1}/{episodes} | Reward: {reward:.4f}\\nTraining Female Accuracy: {train_female_accuracy:.4f}| Training Accuracy: {train_accuracy:.4f}\\nValidation Female Accuracy: {val_female_accuracy:.4f}| Validation Accuracy: {val_accuracy:.4f}\\nTest accuracy: {test_accuracy:.4f} | Test Female Accuracy: {test_female_accuracy:.4f}\\n\\n--------------------------------\\n\")\n",
    "\n",
    "                synthetic_data = []\n",
    "                synthetic_labels = []\n",
    "            else:\n",
    "                reward = mini_reward\n",
    "\n",
    "            next_state = generate_state(x_train, mf_ratio, len(synthetic_data) + 1)\n",
    "            dqn_agent.learn(state, discrete_action, reward, next_state, done)\n",
    "            ppo_agent.learn(state, continuous_action, reward, next_state, done)\n",
    "\n",
    "            rewards.append(reward)\n",
    "            state = next_state\n",
    "\n",
    "    metrics = {\n",
    "        'rewards': rewards,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_female_accuracies': train_female_accuracies,\n",
    "        'val_female_accuracies': val_female_accuracies,\n",
    "        'test_female_accuracies': test_female_accuracies\n",
    "    }\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "    print(f\"Metrics saved to {save_path}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "results = train_agents(x_train, y_train, x_val, y_val, x_test, y_test, dqn_agent, ppo_agent, ffnn_agent)\n",
    "dqn_agent.save(\"dqn_trained_model.pth\")\n",
    "ppo_agent.save(\"ppo_trained_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = evaluate_ffnn(ffnn_agent, x_test, y_test)\n",
    "print(f\"Test Results | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "ffnn_agent_og.train(x_train.to_numpy(), y_train)\n",
    "og_accuracy = evaluate_ffnn(ffnn_agent_og, x_test, y_test)\n",
    "print(f\"No Synthetic Data Test Accuracy: {og_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_training([], [])\n",
    "# visualize_results(dqn_agent, ppo_agent, df)\n",
    "# visualize_preprocessed_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
