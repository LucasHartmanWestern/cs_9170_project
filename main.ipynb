{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import DQNAgent\n",
    "from ppo_agent import PPOAgent\n",
    "from data_processing import preprocess_all_data, load_preprocessed_dataset, get_activity, get_column_units\n",
    "from visualize import visualize_results, visualize_training, visualize_preprocessed_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessed Dataset Info ---\n",
      "Number of rows: 175498\n",
      "Number of columns: 42\n",
      "---------------------------------\n",
      "   Timestamp  Activity ID  Heart Rate  Hand Sensor - Temperature  \\\n",
      "0      37.70            1       100.0                     30.375   \n",
      "1      37.81            1       100.0                     30.375   \n",
      "2      37.92            1       100.0                     30.375   \n",
      "3      38.03            1       100.0                     30.375   \n",
      "4      38.14            1       101.0                     30.375   \n",
      "\n",
      "   Hand Sensor - Accelerometer - X  Hand Sensor - Accelerometer - Y  \\\n",
      "0                          2.30106                          7.25857   \n",
      "1                          2.24615                          7.48180   \n",
      "2                          2.30000                          7.10681   \n",
      "3                          2.49455                          7.52335   \n",
      "4                          2.71654                          8.30596   \n",
      "\n",
      "   Hand Sensor - Accelerometer - Z  Hand Sensor - Gyroscope - X  \\\n",
      "0                          6.09259                    -0.069961   \n",
      "1                          5.55219                    -0.431227   \n",
      "2                          6.09309                     0.075692   \n",
      "3                          6.17157                    -0.259058   \n",
      "4                          4.78671                     0.377115   \n",
      "\n",
      "   Hand Sensor - Gyroscope - Y  Hand Sensor - Gyroscope - Z  ...  \\\n",
      "0                    -0.018328                     0.004582  ...   \n",
      "1                     0.002685                    -0.062964  ...   \n",
      "2                    -0.030792                     0.005246  ...   \n",
      "3                    -0.267895                    -0.038533  ...   \n",
      "4                    -0.023688                    -0.020670  ...   \n",
      "\n",
      "   Ankle Sensor - Magnetometer - Z  Age  Height  Weight  Resting HR  Max HR  \\\n",
      "0                         -57.8847   27     182      83          75     193   \n",
      "1                         -58.4891   27     182      83          75     193   \n",
      "2                         -58.4845   27     182      83          75     193   \n",
      "3                         -58.3608   27     182      83          75     193   \n",
      "4                         -59.0013   27     182      83          75     193   \n",
      "\n",
      "   Sex - Female  Sex - Male  Dominant Hand - Left  Dominant Hand - Right  \n",
      "0             0           1                     0                      1  \n",
      "1             0           1                     0                      1  \n",
      "2             0           1                     0                      1  \n",
      "3             0           1                     0                      1  \n",
      "4             0           1                     0                      1  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed dataset\n",
    "\n",
    "df = load_preprocessed_dataset()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_config = {\n",
    "    'state_size': df.shape[1] - 1,  \n",
    "    'action_size': 2,  \n",
    "    'hidden_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'gamma': 0.99,\n",
    "    'batch_size': 32,\n",
    "    'memory_size': 10000,\n",
    "    'epsilon_start': 1.0,\n",
    "    'epsilon_min': 0.01,\n",
    "    'epsilon_decay': 0.995\n",
    "}\n",
    "\n",
    "ppo_config = {\n",
    "    'state_size': df.shape[1] - 1,  \n",
    "    'action_size': 2,  \n",
    "    'hidden_size': 64,\n",
    "    'lr': 3e-4,\n",
    "    'gamma': 0.99,\n",
    "    'clip_epsilon': 0.2,\n",
    "    'update_epochs': 4,\n",
    "    'batch_size': 64,\n",
    "    'c1': 0.5,\n",
    "    'c2': 0.01\n",
    "}\n",
    "\n",
    "dqn_agent = DQNAgent(**dqn_config)\n",
    "ppo_agent = PPOAgent(**ppo_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN Agent...\n",
      "Training PPO Agent...\n"
     ]
    }
   ],
   "source": [
    "def train_agent(agent, df, agent_name):\n",
    "    if isinstance(agent, DQNAgent):\n",
    "        for _ in range(5):\n",
    "            for index, row in df.iterrows():\n",
    "                state = row[:-1].values\n",
    "                action = agent.predict(state)\n",
    "                reward = row[-1]  # Assuming reward is last column\n",
    "                next_state = state  # DQNAgent does not generate next state; add logic if needed\n",
    "                done = False\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                agent.train()\n",
    "    else:  # PPO\n",
    "        for episode in range(5):\n",
    "            total_reward = 0\n",
    "            for index, row in df.iterrows():\n",
    "                state = row[:-1].values\n",
    "                action = agent.predict(state)\n",
    "                reward = row[-1]  # Assuming reward is last column\n",
    "                done = False\n",
    "                agent.store_transition(state, action, agent.last_log_prob, reward, done, agent.last_value)\n",
    "            agent.train()\n",
    "\n",
    "print(\"Training DQN Agent...\")\n",
    "dqn_agent.save(\"dqn_trained_model.pth\")\n",
    "\n",
    "print(\"Training PPO Agent...\")\n",
    "ppo_agent.save(\"ppo_trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DQN Agent...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting DQN Agent...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m dqn_agent\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn_trained_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtest_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdqn_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDQN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting PPO Agent...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m ppo_agent\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_trained_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mtest_agent\u001b[1;34m(agent, df, agent_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_agent\u001b[39m(agent, df, agent_name):\n\u001b[0;32m      2\u001b[0m     total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      4\u001b[0m         state \u001b[38;5;241m=\u001b[39m row[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m         total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mpredict(state)\n",
      "File \u001b[1;32mc:\\Users\\epigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\epigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:586\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m--> 586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m \u001b[43m_get_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.data_manager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    588\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleBlockManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[1;32mc:\\Users\\epigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_config\\config.py:149\u001b[0m, in \u001b[0;36m_get_option\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    146\u001b[0m key \u001b[38;5;241m=\u001b[39m _get_single_key(pat, silent)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m root, k \u001b[38;5;241m=\u001b[39m \u001b[43m_get_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m root[k]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_agent(agent, df, agent_name):\n",
    "    total_reward = 0\n",
    "    for index, row in df.iterrows():\n",
    "        state = row[:-1].values\n",
    "        total_reward += agent.predict(state)\n",
    "    print(f\"{agent_name} Test Reward: {total_reward}\")\n",
    "\n",
    "print(\"Testing DQN Agent...\")\n",
    "dqn_agent.save(\"dqn_trained_model.pth\")\n",
    "test_agent(dqn_agent, df, \"DQN\")\n",
    "\n",
    "print(\"Testing PPO Agent...\")\n",
    "ppo_agent.save(\"ppo_trained_model.pth\")\n",
    "test_agent(ppo_agent, df, \"PPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_training([], [])\n",
    "# visualize_results(dqn_agent, ppo_agent, df)\n",
    "# visualize_preprocessed_data(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
