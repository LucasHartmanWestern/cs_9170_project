{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from dqn_agent import DQNAgent\n",
    "from ppo_agent import PPOAgent\n",
    "from ffnn_agent import FFNNAgent\n",
    "from data_processing import preprocess_all_data, load_preprocessed_dataset, get_activity, get_column_units, get_xy_from_data\n",
    "from visualize import plot_baseline_mse_histogram, plot_female_mse_histogram, plot_mse_histogram, plot_rewards, plot_rewards_cum_avg, plot_rewards_per_episode\n",
    "from seed import generate_random_seeds, make_deterministic\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(f\"Is CUDA available? {torch.cuda.is_available()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the preprocessed dataset\n",
    "df = load_preprocessed_dataset()\n",
    "target_features = [\"Resting HR\", \"Max HR\", \"Age\", \"Weight\", \"Height\"]\n",
    "\n",
    "# Print unique values of target features\n",
    "for feature in target_features:\n",
    "    print(f\"'{feature}' unique values: {df[feature].unique()}\")\n",
    "\n",
    "# Print unique values of 'Age'\n",
    "print(f\"\\nUnique values of 'Age': {df['Age'].unique()}\")\n",
    "\n",
    "# Print how many rows there are for Activity ID 1 and 2\n",
    "activity_counts = df['Activity ID'].value_counts()\n",
    "print(\"\\nActivity ID counts:\")\n",
    "for act_id in [1, 2]:\n",
    "    count = activity_counts.get(act_id, 0)\n",
    "    print(f\"Activity ID {act_id}: {count} rows\")\n",
    "\n",
    "# Split based on Activity ID\n",
    "df_val = df[df['Activity ID'] == 1].copy()\n",
    "df_test = df[df['Activity ID'] == 2].copy()\n",
    "df_train = df[~df['Activity ID'].isin([1, 2])].copy()\n",
    "\n",
    "# Shuffle train set (optional but recommended)\n",
    "df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Report split sizes\n",
    "print(f\"\\nTrain samples (excluding Activity 1 & 2): {df_train.shape[0]}\")\n",
    "print(f\"Validation samples (Activity 1): {df_val.shape[0]}\")\n",
    "print(f\"Test samples (Activity 2): {df_test.shape[0]}\")\n",
    "\n",
    "# Get X and y splits\n",
    "x_train, y_train = get_xy_from_data(df_train, target_features)\n",
    "x_val, y_val = get_xy_from_data(df_val, target_features)\n",
    "x_test, y_test = get_xy_from_data(df_test, target_features)\n",
    "\n",
    "# Sanity check\n",
    "print(f\"\\nX_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {x_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {x_test.shape}, y_test: {y_test.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize system"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "continuous_columns = [\n",
    "    'Timestamp',  'Hand Sensor - Temperature',\n",
    "    'Hand Sensor - Accelerometer - X', 'Hand Sensor - Accelerometer - Y',\n",
    "    'Hand Sensor - Accelerometer - Z', 'Hand Sensor - Gyroscope - X',\n",
    "    'Hand Sensor - Gyroscope - Y', 'Hand Sensor - Gyroscope - Z',\n",
    "    'Hand Sensor - Magnetometer - X', 'Hand Sensor - Magnetometer - Y',\n",
    "    'Hand Sensor - Magnetometer - Z', 'Chest Sensor - Temperature',\n",
    "    'Chest Sensor - Accelerometer - X', 'Chest Sensor - Accelerometer - Y',\n",
    "    'Chest Sensor - Accelerometer - Z', 'Chest Sensor - Gyroscope - X',\n",
    "    'Chest Sensor - Gyroscope - Y', 'Chest Sensor - Gyroscope - Z',\n",
    "    'Chest Sensor - Magnetometer - X', 'Chest Sensor - Magnetometer - Y',\n",
    "    'Chest Sensor - Magnetometer - Z', 'Ankle Sensor - Temperature',\n",
    "    'Ankle Sensor - Accelerometer - X', 'Ankle Sensor - Accelerometer - Y',\n",
    "    'Ankle Sensor - Accelerometer - Z', 'Ankle Sensor - Gyroscope - X',\n",
    "    'Ankle Sensor - Gyroscope - Y', 'Ankle Sensor - Gyroscope - Z',\n",
    "    'Ankle Sensor - Magnetometer - X', 'Ankle Sensor - Magnetometer - Y',\n",
    "    'Ankle Sensor - Magnetometer - Z'\n",
    "]\n",
    "\n",
    "discrete_columns = [\n",
    "     'Sex - Female', 'Heart Rate', \"Resting HR\", \"Max HR\", \"Weight\", \"Height\"\n",
    "]\n",
    "\n",
    "#discrete action size columns\n",
    "dqn_config = {\n",
    "    'state_size': 5,  \n",
    "    'action_size': len(discrete_columns),  \n",
    "    'hidden_size': 64,\n",
    "    'lr': 1e-2,\n",
    "    'gamma': 0.8,\n",
    "    'batch_size': 64,\n",
    "    'memory_size': 10000,\n",
    "    'epsilon_start': 1.0,\n",
    "    'epsilon_min': 0.01,\n",
    "    'epsilon_decay': 0.995\n",
    "}\n",
    "\n",
    "\n",
    "#continuous\n",
    "ppo_config = {\n",
    "    'state_size': 5,  \n",
    "    'action_size': len(continuous_columns),   \n",
    "    'hidden_size': 64,\n",
    "    'lr': 1e-2,\n",
    "    'gamma': 0.8,\n",
    "    'clip_epsilon': 0.2,\n",
    "    'update_epochs': 10,\n",
    "    'batch_size': 64,\n",
    "    'c1': 0.5,\n",
    "    'c2': 0.01\n",
    "}\n",
    "classes = [1, 2, 3, 17, 16, 13, 4, 7, 6]\n",
    "\n",
    "ffnn_config = {\n",
    "    'input_size': df.shape[1] - 5,\n",
    "    'hidden_sizes': [16, 16],\n",
    "    'output_size': 5,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 20,\n",
    "    'type': 'regression',\n",
    "    'classes': None\n",
    "}\n",
    "\n",
    "# accuracy_reward_multiplier = 10\n",
    "# synthetic_data_amount = 1000\n",
    "# num_episodes = 100\n",
    "\n",
    "accuracy_reward_multiplier = 10\n",
    "synthetic_data_amount = 5\n",
    "num_episodes = 5\n",
    "\n",
    "# dqn_agent = DQNAgent(**dqn_config)\n",
    "# ppo_agent = PPOAgent(**ppo_config)\n",
    "# ffnn_agent = FFNNAgent(**ffnn_config)\n",
    "# ffnn_agent_og = FFNNAgent(**ffnn_config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def evaluate_ffnn(ffnn_agent, data, labels):\n",
    "    if isinstance(data, (pd.DataFrame, pd.Series)):\n",
    "        data = data.to_numpy()\n",
    "    if isinstance(labels, (pd.DataFrame, pd.Series)):\n",
    "        labels = labels.to_numpy()\n",
    "\n",
    "    predictions = ffnn_agent.predict(data)\n",
    "\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "\n",
    "    # Optional: female-specific evaluation\n",
    "    female_mask = data[:, -1] == 1\n",
    "    if female_mask.sum() > 0:\n",
    "        female_preds = predictions[female_mask]\n",
    "        female_labels = labels[female_mask]\n",
    "        female_mse = mean_squared_error(female_labels, female_preds)\n",
    "    else:\n",
    "        female_mse = float('nan')\n",
    "\n",
    "    return mse, mae, female_mse\n",
    "\n",
    "\n",
    "def plot_ffnn_losses(losses):\n",
    "    # Plot training loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.title('FFNN Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ages in df = [27, 25, 31, 24, 26, 23]\n",
    "\n",
    "def generate_state(df, mf_ratio, n_samples):\n",
    "    timestamp = np.random.uniform(df['Timestamp'].min(), df['Timestamp'].max())\n",
    "    male_female_ratio = mf_ratio \n",
    "    num_samples = n_samples\n",
    "    age = np.random.uniform(24, 31)\n",
    "    activity_id = np.random.choice([1, 2])\n",
    "    return np.array([timestamp, male_female_ratio, num_samples, age, activity_id])\n",
    "\n",
    "\n",
    "def compute_mini_reward(synthetic_data, mf_ratio):\n",
    "    column_std = np.std(synthetic_data, axis=0).mean()\n",
    "    gaussian_penalty = np.exp(-((mf_ratio - 0.5) ** 2) / 0.1)\n",
    "    return column_std + gaussian_penalty\n",
    "\n",
    "\n",
    "def train_ffnn_baseline(ffnn_agent, x_train, y_train, x_val, y_val, x_test, y_test, verbose=True):\n",
    "    # Train on real data only\n",
    "    # print(\"\\nTraining FFNN on real data only (no synthetic data)...\")\n",
    "    losses = ffnn_agent.train(x_train.to_numpy(), y_train.to_numpy())\n",
    "    # plot_ffnn_losses(losses)\n",
    "\n",
    "    # Evaluate on all splits\n",
    "    train_mse, train_mae, train_female_mse = evaluate_ffnn(ffnn_agent, x_train, y_train)\n",
    "    val_mse, val_mae, val_female_mse = evaluate_ffnn(ffnn_agent, x_val, y_val)\n",
    "    test_mse, test_mae, test_female_mse = evaluate_ffnn(ffnn_agent, x_test, y_test)\n",
    "\n",
    "    # Print results\n",
    "    if verbose:\n",
    "        print(\"\\n========== FFNN Baseline (No Synthetic Data) ==========\")\n",
    "        print(f\"Train MSE: {train_mse:.4f} | Train MAE: {train_mae:.4f} | Female MSE: {train_female_mse:.4f}\")\n",
    "        print(f\"Val   MSE: {val_mse:.4f} | Val   MAE: {val_mae:.4f} | Female MSE: {val_female_mse:.4f}\")\n",
    "        print(f\"Test  MSE: {test_mse:.4f} | Test  MAE: {test_mae:.4f} | Female MSE: {test_female_mse:.4f}\")\n",
    "        print(\"=======================================================\\n\")\n",
    "\n",
    "    return {\n",
    "        \"train\": (train_mse, train_mae, train_female_mse),\n",
    "        \"val\": (val_mse, val_mae, val_female_mse),\n",
    "        \"test\": (test_mse, test_mae, test_female_mse),\n",
    "    }\n",
    "\n",
    "\n",
    "def train_agents(x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "                 dqn_agent, ppo_agent, ffnn_agent, episodes=num_episodes,\n",
    "                 save_path='./experiments', verbose=True):\n",
    "\n",
    "    # Normalize y arrays to shape (n, 1)\n",
    "    # for var in ['y_train', 'y_val', 'y_test']:\n",
    "    #     val = locals()[var]\n",
    "    #     if isinstance(val, pd.Series):\n",
    "    #         locals()[var] = val.to_numpy().reshape(-1, 1)\n",
    "    #     elif isinstance(val, pd.DataFrame):\n",
    "    #         locals()[var] = val.to_numpy()\n",
    "\n",
    "    rewards = []\n",
    "    val_accuracies = []\n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "    val_female_accuracies = []\n",
    "    test_female_accuracies = []\n",
    "    train_female_accuracies = []\n",
    "\n",
    "    synthetic_data = []\n",
    "    synthetic_labels = []\n",
    "\n",
    "    # Initial male-female ratio\n",
    "    sex_female_idx = x_train.columns.get_loc('Sex - Female')\n",
    "    mf_ratio = np.mean(x_train.iloc[:, sex_female_idx])\n",
    "    state = generate_state(x_train, mf_ratio, 0)\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Episode {episode + 1}/{episodes}: Generating Synthetic Data\")\n",
    "            \n",
    "        for i in range(synthetic_data_amount):\n",
    "            if synthetic_data:\n",
    "                synthetic_array = np.array(synthetic_data)\n",
    "                if synthetic_array.ndim == 1:\n",
    "                    synthetic_array = synthetic_array.reshape(1, -1)\n",
    "                combined_array = np.vstack([x_train.to_numpy(), synthetic_array])\n",
    "                combined = pd.DataFrame(combined_array, columns=x_train.columns)\n",
    "            else:\n",
    "                combined = x_train.copy()\n",
    "\n",
    "            sex_female_idx = combined.columns.get_loc('Sex - Female')\n",
    "            mf_ratio = np.mean(combined.iloc[:, sex_female_idx])\n",
    "\n",
    "            # Predict actions from RL agents\n",
    "            discrete_action = np.array(dqn_agent.predict(state), ndmin=1).flatten()\n",
    "\n",
    "            # First 2 values are features: 'Sex - Female', 'Heart Rate'\n",
    "            sex_value = discrete_action[0]\n",
    "            heart_rate = discrete_action[1]\n",
    "\n",
    "            # Predicted target values: Resting HR, Max HR, Weight, Height (4 values)\n",
    "            predicted_targets = discrete_action[2:6]\n",
    "\n",
    "            # Age comes from the state (4th element)\n",
    "            age_from_state = state[3]\n",
    "\n",
    "            # Combine into full target: [Resting HR, Max HR, Age, Weight, Height]\n",
    "            target_values = np.insert(predicted_targets, 2, age_from_state)  # insert age at index 2\n",
    "            # Resulting shape: (5,) â€” matches label format\n",
    "\n",
    "            # Predict continuous features\n",
    "            continuous_action = np.array(ppo_agent.predict(state), ndmin=1)  # shape (1, num_continuous_features)\n",
    "\n",
    "            # Create synthetic feature row\n",
    "            synthetic_row = np.zeros(x_train.shape[1])\n",
    "\n",
    "            # Get column indices\n",
    "            discrete_indices = x_train.columns.get_indexer(['Sex - Female', 'Heart Rate'])\n",
    "            continuous_indices = x_train.columns.get_indexer(continuous_columns)\n",
    "\n",
    "            # Assign values to synthetic row\n",
    "            synthetic_row[discrete_indices[0]] = sex_value\n",
    "            synthetic_row[discrete_indices[1]] = heart_rate\n",
    "            synthetic_row[continuous_indices] = continuous_action.flatten()\n",
    "\n",
    "            # Add to synthetic dataset\n",
    "            synthetic_data.append(synthetic_row)\n",
    "            synthetic_labels.append(target_values)\n",
    "\n",
    "            mini_reward = compute_mini_reward(np.array(synthetic_data), mf_ratio)\n",
    "            done = i == synthetic_data_amount - 1\n",
    "\n",
    "\n",
    "            if done:\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Episode {episode + 1}/{episodes}: Training FFNN\")\n",
    "                \n",
    "                ffnn_agent.reset()\n",
    "\n",
    "                synthetic_data_np = np.array(synthetic_data)                    # (n_samples, num_features)\n",
    "                synthetic_labels_np = np.array(synthetic_labels).reshape(-1, 5) # (n_samples, 5)\n",
    "\n",
    "                combined_data = np.vstack([x_train.to_numpy(), synthetic_data_np])\n",
    "                combined_labels = np.vstack([y_train, synthetic_labels_np])\n",
    "\n",
    "\n",
    "                # Shuffle combined training data\n",
    "                indices = np.arange(combined_data.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "                combined_data = combined_data[indices]\n",
    "                combined_labels = combined_labels[indices]\n",
    "\n",
    "                # Train FFNN\n",
    "                losses = ffnn_agent.train(combined_data, combined_labels)\n",
    "                # plot_ffnn_losses(losses)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Episode {episode + 1}/{episodes}: Evaluating FFNN\")\n",
    "\n",
    "                train_mse, train_mae, train_female_mse = evaluate_ffnn(ffnn_agent, x_train, y_train)\n",
    "                val_mse, val_mae, val_female_mse = evaluate_ffnn(ffnn_agent, x_val, y_val)\n",
    "                test_mse, test_mae, test_female_mse = evaluate_ffnn(ffnn_agent, x_test, y_test)\n",
    "\n",
    "                # Reward is based on validation performance and mini reward\n",
    "                reward = (accuracy_reward_multiplier * val_mse * -1) + (mini_reward)\n",
    "\n",
    "                train_accuracies.append(train_mse)\n",
    "                val_accuracies.append(val_mse)\n",
    "                test_accuracies.append(test_mse)\n",
    "                train_female_accuracies.append(train_female_mse)\n",
    "                val_female_accuracies.append(val_female_mse)\n",
    "                test_female_accuracies.append(test_female_mse)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Episode {episode + 1}/{episodes} | Reward: {reward:.4f}\")\n",
    "                    print(f\"Train MSE: {train_mse:.4f} | Train Female MSE: {train_female_mse:.4f}\")\n",
    "                    print(f\"Val MSE: {val_mse:.4f} | Val Female MSE: {val_female_mse:.4f}\")\n",
    "                    print(f\"Test MSE: {test_mse:.4f} | Test Female MSE: {test_female_mse:.4f}\")\n",
    "                    print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "                synthetic_data = []\n",
    "                synthetic_labels = []\n",
    "            else:\n",
    "                reward = mini_reward\n",
    "\n",
    "            next_state = generate_state(x_train, mf_ratio, len(synthetic_data) + 1)\n",
    "            dqn_agent.learn(state, discrete_action, reward, next_state, done)\n",
    "            ppo_agent.learn(state, continuous_action, reward, next_state, done)\n",
    "\n",
    "            rewards.append(reward)\n",
    "            state = next_state\n",
    "\n",
    "        metrics = {\n",
    "            'rewards': rewards,\n",
    "            'train_mse': train_accuracies,\n",
    "            'val_mse': val_accuracies,\n",
    "            'test_mse': test_accuracies,\n",
    "            'train_female_mse': train_female_accuracies,\n",
    "            'val_female_mse': val_female_accuracies,\n",
    "            'test_female_mse': test_female_accuracies\n",
    "        }\n",
    "\n",
    "\n",
    "    with open(os.path.join(save_path, 'training_metrics.json'), 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "    print(f\"Metrics saved to {save_path}\")\n",
    "    \n",
    "    dqn_agent.save(os.path.join(save_path, \"dqn_trained_model.pth\"))\n",
    "    ppo_agent.save(os.path.join(save_path, \"ppo_trained_model.pth\"))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# baseline_results = train_ffnn_baseline(ffnn_agent_og, x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "# results = train_agents(x_train, y_train, x_val, y_val, x_test, y_test, dqn_agent, ppo_agent, ffnn_agent)\n",
    "# dqn_agent.save(\"dqn_trained_model.pth\")\n",
    "# ppo_agent.save(\"ppo_trained_model.pth\")\n",
    "\n",
    "\n",
    "def write_print(file: str, line: str):\n",
    "    print(line)\n",
    "    with open(file, 'a') as f:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "def run_deterministic_experiments(num_experiments):\n",
    "    \n",
    "    seeds = generate_random_seeds(num_seeds=num_experiments)\n",
    "    \n",
    "    for trial in range(len(seeds)):\n",
    "        save_location = f\"C:\\\\Users\\\\NickS\\\\Dev\\\\cs_9170_project\\\\experiments\\\\trial_{trial+1}\"\n",
    "        os.makedirs(save_location, exist_ok=True)\n",
    "        make_deterministic(seeds[trial])\n",
    "    \n",
    "        # set up agents\n",
    "        dqn_agent = DQNAgent(**dqn_config)\n",
    "        ppo_agent = PPOAgent(**ppo_config)\n",
    "        ffnn_agent = FFNNAgent(**ffnn_config)\n",
    "        ffnn_agent_og = FFNNAgent(**ffnn_config)\n",
    "        \n",
    "        # set up results file\n",
    "        results_file = os.path.join(save_location, 'results.txt')\n",
    "        open(results_file, 'w+').close()\n",
    "        \n",
    "        # run current trial\n",
    "        write_print(results_file, f\"\\n\\n================= Trial {trial+1} ===================\")\n",
    "        write_print(results_file, f\"\\nUsing seed: {seeds[trial]}\")\n",
    "        \n",
    "        baseline_results = train_ffnn_baseline(ffnn_agent_og, x_train, y_train, x_val, y_val, x_test, y_test, verbose=False)\n",
    "        write_print(results_file, \"\\n========== FFNN Baseline (No Synthetic Data)\")\n",
    "        write_print(results_file, f\"[Training] MSE: {baseline_results[\"train\"][0]:.4f} | Female MSE: {baseline_results[\"train\"][-1]:.4f}\")\n",
    "        write_print(results_file, f\"[Validation] MSE: {baseline_results[\"val\"][0]:.4f} | Female MSE: {baseline_results[\"val\"][-1]:.4f}\")\n",
    "        write_print(results_file, f\"[Testing] MSE: {baseline_results[\"test\"][0]:.4f} | Female MSE: {baseline_results[\"test\"][-1]:.4f}\")\n",
    "        \n",
    "        plot_baseline_mse_histogram(baseline_results, save_location, False)\n",
    "        \n",
    "        write_print(results_file, \"\\n========== FFNN Trained (With Synthetic Data)\")\n",
    "        results = train_agents(x_train, y_train, x_val, y_val, x_test, y_test, dqn_agent, ppo_agent, ffnn_agent, save_path=save_location, verbose=False)\n",
    "        write_print(results_file, f\"Episode {num_episodes}/{num_episodes} | Reward: {results[\"rewards\"][-1]:.4f}\")\n",
    "        write_print(results_file, f\"[Training] MSE: {results[\"train_mse\"][-1]:.4f} | Female MSE: {results[\"train_female_mse\"][-1]:.4f}\")\n",
    "        write_print(results_file, f\"[Validation] MSE: {results[\"val_mse\"][-1]:.4f} | Female MSE: {results[\"val_female_mse\"][-1]:.4f}\")\n",
    "        write_print(results_file, f\"[Testing] MSE: {results[\"test_mse\"][-1]:.4f} | Female MSE: {results[\"test_female_mse\"][-1]:.4f}\")\n",
    "        \n",
    "        metrics_file_location = os.path.join(save_location, \"training_metrics.json\")\n",
    "        plot_rewards(metrics_file_location, save_location, False)\n",
    "        plot_rewards_per_episode(metrics_file_location, save_location, False)\n",
    "        plot_rewards_cum_avg(metrics_file_location, save_location, False)\n",
    "        plot_mse_histogram(metrics_file_location, save_location, False)\n",
    "        plot_female_mse_histogram(metrics_file_location, save_location, False)\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Train and Test Experiments\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "run_deterministic_experiments(num_experiments=3)\n",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
