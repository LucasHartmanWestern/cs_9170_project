{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import DQNAgent\n",
    "from ppo_agent import PPOAgent\n",
    "from ffnn_agent import FFNNAgent\n",
    "from data_processing import preprocess_all_data, load_preprocessed_dataset, get_activity, get_column_units\n",
    "from data_processing import load_preprocessed_dataset, get_biased_feature_percentage, train_test_split_data, get_xy_from_data, get_activity, get_column_units\n",
    "from visualize import visualize_results, visualize_training, visualize_preprocessed_data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset\n",
    "df = load_preprocessed_dataset()\n",
    "\n",
    "# Print unique values of Activity ID\n",
    "unique_activity_ids = df['Activity ID'].unique()\n",
    "print(\"Unique Activity IDs:\", unique_activity_ids)\n",
    "print(df.head())\n",
    "\n",
    "# Get percentage of biased feature\n",
    "biased_feature_percentage = get_biased_feature_percentage(df, print_result=False)\n",
    "\n",
    "# Split into 70% train, 15% val, 15% test with stratification\n",
    "df_train, df_temp = train_test_split(\n",
    "    df, test_size=0.30, stratify=df['Sex - Female'], random_state=42\n",
    ")\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp, test_size=0.50, stratify=df_temp['Sex - Female'], random_state=42\n",
    ")\n",
    "\n",
    "# Get X and y data from training, validation, and testing sets\n",
    "x_train, y_train = get_xy_from_data(df_train)\n",
    "x_val, y_val = get_xy_from_data(df_val)\n",
    "x_test, y_test = get_xy_from_data(df_test)\n",
    "\n",
    "# Make y_train 2d\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "y_val = y_val.values.reshape(-1, 1)\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = [\n",
    "    'Timestamp', 'Heart Rate', 'Hand Sensor - Temperature',\n",
    "    'Hand Sensor - Accelerometer - X', 'Hand Sensor - Accelerometer - Y',\n",
    "    'Hand Sensor - Accelerometer - Z', 'Hand Sensor - Gyroscope - X',\n",
    "    'Hand Sensor - Gyroscope - Y', 'Hand Sensor - Gyroscope - Z',\n",
    "    'Hand Sensor - Magnetometer - X', 'Hand Sensor - Magnetometer - Y',\n",
    "    'Hand Sensor - Magnetometer - Z', 'Chest Sensor - Temperature',\n",
    "    'Chest Sensor - Accelerometer - X', 'Chest Sensor - Accelerometer - Y',\n",
    "    'Chest Sensor - Accelerometer - Z', 'Chest Sensor - Gyroscope - X',\n",
    "    'Chest Sensor - Gyroscope - Y', 'Chest Sensor - Gyroscope - Z',\n",
    "    'Chest Sensor - Magnetometer - X', 'Chest Sensor - Magnetometer - Y',\n",
    "    'Chest Sensor - Magnetometer - Z', 'Ankle Sensor - Temperature',\n",
    "    'Ankle Sensor - Accelerometer - X', 'Ankle Sensor - Accelerometer - Y',\n",
    "    'Ankle Sensor - Accelerometer - Z', 'Ankle Sensor - Gyroscope - X',\n",
    "    'Ankle Sensor - Gyroscope - Y', 'Ankle Sensor - Gyroscope - Z',\n",
    "    'Ankle Sensor - Magnetometer - X', 'Ankle Sensor - Magnetometer - Y',\n",
    "    'Ankle Sensor - Magnetometer - Z', 'Height', 'Weight',\n",
    "    'Resting HR', 'Max HR'\n",
    "]\n",
    "\n",
    "discrete_columns = [\n",
    "    'Age', 'Sex - Female'\n",
    "]\n",
    "\n",
    "#discrete action size columns\n",
    "dqn_config = {\n",
    "    'state_size': 5,  \n",
    "    'action_size': len(discrete_columns),  \n",
    "    'hidden_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'gamma': 0.99,\n",
    "    'batch_size': 32,\n",
    "    'memory_size': 10000,\n",
    "    'epsilon_start': 1.0,\n",
    "    'epsilon_min': 0.01,\n",
    "    'epsilon_decay': 0.995\n",
    "}\n",
    "\n",
    "\n",
    "#continuous\n",
    "ppo_config = {\n",
    "    'state_size': 5,  \n",
    "    'action_size': len(continuous_columns),   \n",
    "    'hidden_size': 64,\n",
    "    'lr': 3e-4,\n",
    "    'gamma': 0.99,\n",
    "    'clip_epsilon': 0.2,\n",
    "    'update_epochs': 4,\n",
    "    'batch_size': 64,\n",
    "    'c1': 0.5,\n",
    "    'c2': 0.01\n",
    "}\n",
    "classes = [1, 2, 3, 17, 16, 13, 4, 7, 6]\n",
    "ffnn_config = {\n",
    "    'input_size': df.shape[1] - 1,\n",
    "    'hidden_sizes': [64, 64],\n",
    "    'output_size': len(classes),\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'type': 'classification',\n",
    "    'classes': classes\n",
    "}\n",
    "\n",
    "synthetic_data_amount = 100\n",
    "num_episodes = 10000\n",
    "\n",
    "dqn_agent = DQNAgent(**dqn_config)\n",
    "ppo_agent = PPOAgent(**ppo_config)\n",
    "ffnn_agent = FFNNAgent(**ffnn_config)\n",
    "ffnn_agent_og = FFNNAgent(**ffnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "\n",
    "def evaluate_ffnn(ffnn_agent, data, labels):\n",
    "    # Ensure data and labels are NumPy arrays\n",
    "    if isinstance(data, (pd.DataFrame, pd.Series)):\n",
    "        data = data.to_numpy()\n",
    "    if isinstance(labels, (pd.Series, pd.DataFrame)):\n",
    "        labels = labels.to_numpy().reshape(-1)\n",
    "\n",
    "    # Convert to tensors\n",
    "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long).view(-1)  # <- ensures 1D shape\n",
    "\n",
    "\n",
    "    device = next(ffnn_agent.model.parameters()).device\n",
    "    data_tensor = data_tensor.to(device)\n",
    "    labels_tensor = labels_tensor.to(device)\n",
    "\n",
    "    # Model prediction\n",
    "    ffnn_agent.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = ffnn_agent.model(data_tensor)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    # Sanity check\n",
    "    if predicted_classes.shape != labels_tensor.shape:\n",
    "        print(\"Shape mismatch:\", predicted_classes.shape, labels_tensor.shape)\n",
    "        labels_tensor = labels_tensor.view(-1)\n",
    "        predicted_classes = predicted_classes.view(-1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    correct = (predicted_classes == labels_tensor).sum().item()\n",
    "    total = labels_tensor.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Correct: {correct}, Total: {total}, Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_state(df, mf_ratio, n_samples):\n",
    "    timestamp = np.random.uniform(df['Timestamp'].min(), df['Timestamp'].max())\n",
    "    male_female_ratio = mf_ratio \n",
    "    num_samples = n_samples\n",
    "    age = np.random.uniform(df['Age'].min(), df['Age'].max())\n",
    "    activity_id = np.random.choice([1, 2, 3, 17, 16, 13, 4, 7, 6])\n",
    "    return np.array([timestamp, male_female_ratio, num_samples, age, activity_id])\n",
    "\n",
    "\n",
    "def compute_mini_reward(synthetic_data, mf_ratio):\n",
    "    column_std = np.std(synthetic_data, axis=0).mean()\n",
    "    gaussian_penalty = np.exp(-((mf_ratio - 0.5) ** 2) / 0.1)\n",
    "    return column_std + gaussian_penalty\n",
    "\n",
    "\n",
    "def train_agents(x_train, y_train, x_val, y_val, x_test, y_test,\n",
    "                 dqn_agent, ppo_agent, ffnn_agent, episodes=num_episodes,\n",
    "                 save_path='training_metrics.json'):\n",
    "\n",
    "    # Normalize y arrays to shape (n, 1)\n",
    "    for var in ['y_train', 'y_val', 'y_test']:\n",
    "        val = locals()[var]\n",
    "        if isinstance(val, pd.Series):\n",
    "            locals()[var] = val.to_numpy().reshape(-1, 1)\n",
    "        elif isinstance(val, pd.DataFrame):\n",
    "            locals()[var] = val.to_numpy()\n",
    "\n",
    "    rewards = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    synthetic_data = []\n",
    "    synthetic_labels = []\n",
    "\n",
    "    # Initial male-female ratio\n",
    "    sex_female_idx = x_train.columns.get_loc('Sex - Female')\n",
    "    mf_ratio = np.mean(x_train.iloc[:, sex_female_idx])\n",
    "    state = generate_state(x_train, mf_ratio, 0)\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        if synthetic_data:\n",
    "            synthetic_array = np.array(synthetic_data)\n",
    "            if synthetic_array.ndim == 1:\n",
    "                synthetic_array = synthetic_array.reshape(1, -1)\n",
    "            combined_array = np.vstack([x_train.to_numpy(), synthetic_array])\n",
    "            combined = pd.DataFrame(combined_array, columns=x_train.columns)\n",
    "        else:\n",
    "            combined = x_train.copy()\n",
    "\n",
    "        sex_female_idx = combined.columns.get_loc('Sex - Female')\n",
    "        mf_ratio = np.mean(combined.iloc[:, sex_female_idx])\n",
    "\n",
    "        discrete_action = np.array(dqn_agent.predict(state), ndmin=1)\n",
    "        continuous_action = np.array(ppo_agent.predict(state), ndmin=1)\n",
    "\n",
    "        synthetic_row = np.zeros(x_train.shape[1])\n",
    "        discrete_indices = x_train.columns.get_indexer(discrete_columns)\n",
    "        continuous_indices = x_train.columns.get_indexer(continuous_columns)\n",
    "        synthetic_row[discrete_indices] = discrete_action\n",
    "        synthetic_row[continuous_indices] = continuous_action\n",
    "\n",
    "        synthetic_data.append(synthetic_row)\n",
    "        synthetic_labels.append(state[4])  # activity ID\n",
    "\n",
    "        mini_reward = compute_mini_reward(np.array(synthetic_data), mf_ratio)\n",
    "        done = len(synthetic_data) >= synthetic_data_amount\n",
    "\n",
    "        if done:\n",
    "            synthetic_data_np = np.array(synthetic_data)\n",
    "            synthetic_labels_np = np.array(synthetic_labels).reshape(-1, 1)\n",
    "\n",
    "            combined_data = np.vstack([x_train.to_numpy(), synthetic_data_np])\n",
    "            combined_labels = np.vstack([y_train, synthetic_labels_np])\n",
    "\n",
    "            # Shuffle combined training data\n",
    "            indices = np.arange(combined_data.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            combined_data = combined_data[indices]\n",
    "            combined_labels = combined_labels[indices]\n",
    "\n",
    "            # Train FFNN\n",
    "            ffnn_agent.train(combined_data, combined_labels)\n",
    "\n",
    "\n",
    "            accuracy = evaluate_ffnn(ffnn_agent, x_val, y_val)\n",
    "            test_accuracy = evaluate_ffnn(ffnn_agent, x_test, y_test)\n",
    "\n",
    "            reward = accuracy\n",
    "            reward += mini_reward\n",
    "            accuracies.append(accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "            print(f\"Episode {episode + 1}/{episodes} | Reward: {reward:.4f} | Validation Accuracy: {accuracy:.4f} | Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            synthetic_data = []\n",
    "            synthetic_labels = []\n",
    "        else:\n",
    "            reward = mini_reward\n",
    "\n",
    "        next_state = generate_state(x_train, mf_ratio, len(synthetic_data) + 1)\n",
    "        dqn_agent.learn(state, discrete_action, reward, next_state, done)\n",
    "        ppo_agent.learn(state, continuous_action, reward, next_state, done)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        state = next_state\n",
    "\n",
    "    metrics = {\n",
    "        'rewards': rewards,\n",
    "        'accuracies': accuracies,\n",
    "        'test_accuracies': test_accuracies\n",
    "    }\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "    print(f\"Metrics saved to {save_path}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "results = train_agents(x_train, y_train, x_val, y_val, x_test, y_test, dqn_agent, ppo_agent, ffnn_agent)\n",
    "dqn_agent.save(\"dqn_trained_model.pth\")\n",
    "ppo_agent.save(\"ppo_trained_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = evaluate_ffnn(ffnn_agent, x_test, y_test)\n",
    "print(f\"Test Results | Reward: {reward:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "ffnn_agent_og.train(x_train.to_numpy(), y_train)\n",
    "og_accuracy = evaluate_ffnn(ffnn_agent_og, x_test, y_test)\n",
    "print(f\"No Synthetic Data Test Accuracy: {og_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_training([], [])\n",
    "# visualize_results(dqn_agent, ppo_agent, df)\n",
    "# visualize_preprocessed_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
